# ü§ñ IA Conversacional Multiplataforma para Atendimento Autom√°tico

**Autor:** Gabriel Demetrios Lafis

Esta solu√ß√£o oferece um **Assistente de IA Conversacional** robusto e flex√≠vel, projetado para atender clientes automaticamente em **m√∫ltiplos canais**. O projeto √© apresentado em duas vers√µes de backend (Python e Node.js/JavaScript) para m√°xima adaptabilidade, al√©m de um frontend web simples para demonstra√ß√£o.

---

## üéØ Vis√£o Geral do Projeto

A arquitetura √© baseada em uma **API central** que gerencia a l√≥gica de conversa√ß√£o com a IA (utilizando a API do OpenAI) e mant√©m o contexto de cada usu√°rio. Essa API √© o ponto de integra√ß√£o para todos os canais de comunica√ß√£o.

### üèóÔ∏è Arquitetura

| Componente | Fun√ß√£o Principal | Tecnologias |
| :--- | :--- | :--- |
| **Backend (API)** | Processa mensagens, interage com a IA, mant√©m o hist√≥rico de conversa√ß√£o e exp√µe endpoints para os canais. | **Python (Flask)** ou **Node.js (Express)** |
| **IA (Modelo)** | Gera respostas inteligentes, emp√°ticas e contextuais. | **OpenAI GPT-3.5/GPT-4** (Configur√°vel) |
| **Canais** | Pontos de contato com o cliente. | Web, WhatsApp (via Twilio), Telegram, Instagram/Facebook (via Webhooks) |
| **Frontend** | Interface de demonstra√ß√£o web. | HTML, CSS, JavaScript |

### ‚ú® Recursos Principais

*   **Multiplataforma:** Suporte nativo para Web, WhatsApp, Telegram, e arquitetura pronta para outros canais (Instagram, Facebook Messenger).
*   **Contexto de Conversa:** A IA mant√©m o hist√≥rico recente da conversa, permitindo intera√ß√µes fluidas e relevantes.
*   **Versatilidade:** Implementa√ß√µes completas em **Python** (com Flask) e **Node.js** (com Express).
*   **F√°cil Implanta√ß√£o:** Configura√ß√£o via vari√°veis de ambiente (`.env`) e suporte a **Docker** para deploy r√°pido.

---

## üöÄ Configura√ß√£o e Instala√ß√£o

Para rodar o projeto, voc√™ precisar√° de:

1.  **Chave de API do OpenAI:** Necess√°ria para o funcionamento da IA.
2.  **Docker** (Recomendado para deploy r√°pido) ou **Python 3.11+** / **Node.js 20+** (Para desenvolvimento local).

### 1. Clonar o Reposit√≥rio

\`\`\`bash
# Certifique-se de ter o git instalado
git clone https://github.com/galafis/IA-Conversacional-Multiplataforma.git
cd IA-Conversacional-Multiplataforma
\`\`\`

### 2. Configurar Vari√°veis de Ambiente

Em cada pasta de backend (`python_backend` e `nodejs_backend`), voc√™ encontrar√° um arquivo \`.env.example\`.

1.  Copie o arquivo para \`.env\`:

    \`\`\`bash
    cp python_backend/.env.example python_backend/.env
    cp nodejs_backend/.env.example nodejs_backend/.env
    \`\`\`

2.  Edite o arquivo \`.env\` e adicione sua chave de API do OpenAI:

    \`\`\`bash
    # Exemplo de .env
    OPENAI_API_KEY=sua_chave_aqui
    AI_SYSTEM_PROMPT=Voc√™ √© um assistente de atendimento ao cliente amig√°vel e profissional...
    # ... outras configura√ß√µes de canal (Twilio, Telegram)
    \`\`\`

---

## üíª Op√ß√£o A: Backend em Python (Flask)

### 1. Instala√ß√£o

\`\`\`bash
cd python_backend
pip install -r requirements.txt
\`\`\`

### 2. Execu√ß√£o

\`\`\`bash
# O servidor ser√° iniciado na porta 5000 (ou FLASK_PORT no .env)
python app.py
\`\`\`

### 3. Endpoints Principais

| M√©todo | Rota | Descri√ß√£o |
| :--- | :--- | :--- |
| \`POST\` | \`/api/chat\` | Envia uma mensagem para a IA e recebe a resposta. |
| \`GET\` | \`/health\` | Verifica a sa√∫de da API. |
| \`GET\` | \`/api/conversation/<user_id>/<channel>\` | Retorna o hist√≥rico de conversa. |
| \`DELETE\` | \`/api/conversation/<user_id>/<channel>\` | Limpa o hist√≥rico de conversa. |

---

## üíª Op√ß√£o B: Backend em Node.js (Express)

### 1. Instala√ß√£o

\`\`\`bash
cd nodejs_backend
npm install
\`\`\`

### 2. Execu√ß√£o

\`\`\`bash
# O servidor ser√° iniciado na porta 3000 (ou PORT no .env)
npm start
\`\`\`

### 3. Endpoints Principais

Os endpoints s√£o os mesmos da vers√£o Python, mas o servidor Node.js √© executado por padr√£o na porta **3000**.

---

## üåê Frontend Web (Demonstra√ß√£o)

O frontend √© um simples chat widget em HTML, CSS e JavaScript puro, projetado para testar a API de forma visual.

1.  **Inicie um dos Backends** (Python ou Node.js).
2.  Navegue at√© a pasta \`web_frontend\`.
3.  Abra o arquivo \`index.html\` diretamente no seu navegador.

O chat widget permite:
*   Testar a conex√£o com a API.
*   Mudar a URL da API (padr√£o: \`http://localhost:3000\` - mude para \`http://localhost:5000\` se usar Python).
*   Simular diferentes canais (Web, WhatsApp, Telegram) e IDs de usu√°rio.
*   Enviar mensagens e visualizar as respostas da IA.

---

## üîó Integra√ß√£o com Canais

A arquitetura da API est√° pronta para receber webhooks dos principais provedores.

### WhatsApp (via Twilio)

1.  Configure uma conta no **Twilio** e um n√∫mero de WhatsApp.
2.  No console do Twilio, defina a URL do **Webhook** para a rota \`/api/whatsapp/webhook\` da sua API (ex: \`https://seuservidor.com/api/whatsapp/webhook\`).
3.  Preencha as vari√°veis de ambiente \`TWILIO_ACCOUNT_SID\`, \`TWILIO_AUTH_TOKEN\` e \`TWILIO_PHONE_NUMBER\` no arquivo \`.env\`.

### Telegram

1.  Crie um novo bot com o **BotFather** no Telegram e obtenha o \`TELEGRAM_BOT_TOKEN\`.
2.  Defina o Webhook do seu bot para a rota \`/api/telegram/webhook\` da sua API:

    \`\`\`bash
    # Exemplo de comando para definir o webhook
    curl -F "url=https://seuservidor.com/api/telegram/webhook" "https://api.telegram.org/bot<TELEGRAM_BOT_TOKEN>/setWebhook"
    \`\`\`

3.  Preencha a vari√°vel de ambiente \`TELEGRAM_BOT_TOKEN\` no arquivo \`.env\`.

---

## üê≥ Implanta√ß√£o com Docker (Recomendado)

O uso de Docker simplifica a instala√ß√£o e garante que o ambiente de execu√ß√£o seja id√™ntico ao de desenvolvimento.

### 1. Docker Compose

Crie um arquivo \`docker-compose.yml\` na raiz do projeto (fora das pastas \`python_backend\` e \`nodejs_backend\`) para gerenciar ambos os servi√ßos.

\`\`\`yaml
# docker-compose.yml
version: '3.8'

services:
  # Exemplo 1: Backend em Python
  python-api:
    build: ./python_backend
    container_name: ia-python-api
    ports:
      - "5000:5000"
    volumes:
      - ./python_backend/.env:/app/.env
    restart: always

  # Exemplo 2: Backend em Node.js
  nodejs-api:
    build: ./nodejs_backend
    container_name: ia-nodejs-api
    ports:
      - "3000:3000"
    volumes:
      - ./nodejs_backend/.env:/app/.env
    restart: always

  # Frontend Web (opcional, para servir o index.html)
  frontend:
    image: nginx:alpine
    container_name: ia-web-frontend
    ports:
      - "80:80"
    volumes:
      - ./web_frontend:/usr/share/nginx/html
    depends_on:
      - nodejs-api # Ou python-api
\`\`\`

### 2. Execu√ß√£o com Docker

\`\`\`bash
# Subir os servi√ßos (escolha apenas um backend para rodar)
docker-compose up -d --build python-api frontend

# OU

docker-compose up -d --build nodejs-api frontend
\`\`\`

Acesse o frontend em \`http://localhost\` e a API em \`http://localhost:5000\` (Python) ou \`http://localhost:3000\` (Node.js).

---

## üìù Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT.
\`\`\`

